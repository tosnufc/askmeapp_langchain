# Askmeapp with LangChain
For Studying LangChain. Not for production use.
Local LLM with Ollama app is in local_llm_askme folder (Reference: https://medium.com/@vndee.huynh/build-your-own-rag-and-run-it-locally-langchain-ollama-streamlit-181d42805895)
<img width="2533" alt="image" src="https://github.com/tosnufc/askmeapp_langchain/assets/92618784/1ab76f54-0ddb-4805-93b4-ddb88c20313a">
